{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f39adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.abspath(os.curdir).replace('notebooks',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff96ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./data/fewrel/train_wiki.json','r') as data:\n",
    "    js_ls = json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "baa3126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModel\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "embeddings_to_zero = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e6abd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens = ['[ENTITY1]','[END_ENTITY1]','[ENTITY2]','[END_ENTITY2]']\n",
    "\n",
    "any(100==tokenizer.convert_tokens_to_ids(t) for t in new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d815a364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e730726a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f0eab02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4477f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./bert-base-uncased-mtb-rnd/tokenizer_config.json',\n",
       " './bert-base-uncased-mtb-rnd/special_tokens_map.json',\n",
       " './bert-base-uncased-mtb-rnd/vocab.txt',\n",
       " './bert-base-uncased-mtb-rnd/added_tokens.json')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ae94bb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mer',\n",
       " '##pati',\n",
       " 'flight',\n",
       " '106',\n",
       " 'departed',\n",
       " 'jakarta',\n",
       " '(',\n",
       " 'c',\n",
       " '##g',\n",
       " '##k',\n",
       " ')',\n",
       " 'on',\n",
       " 'a',\n",
       " 'domestic',\n",
       " 'flight',\n",
       " 'to',\n",
       " 'tan',\n",
       " '##jun',\n",
       " '##g',\n",
       " 'panda',\n",
       " '##n',\n",
       " '(',\n",
       " 't',\n",
       " '##j',\n",
       " '##q',\n",
       " ')',\n",
       " '.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = ' '.join(js_ls['P931'][0]['tokens'])\n",
    "\n",
    "tokenizer.tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add\n",
    "all_sents_pair\n",
    "# Add the same number of negative examples from outside of the sentence pair\n",
    "all_sents_ex_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b570d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6bd9e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.ngram_utils import find_token_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "496d9257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 't', '##j', '##q', '[SEP]']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('TJQ').tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a78450c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[16, 21]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_token_range(tokenizer.tokenize(txt),tokenizer.tokenize('tanjung pandan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98dca654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1_id = tokenizer.convert_tokens_to_ids('[ENTITY1]')\n",
    "e1_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c310f563",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(29000, 768)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "871e3dfd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385fadd018764813819aba948bbe5672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4fe14f21b54895a1b578e62de1f8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7234ad7913db42fcbeb41eec0e7dc1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2150a0a399a4d98b28fb29a9f9bafa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e309a9bd6d454962919a0abf47a43adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28996\n",
      "29000\n",
      "tensor([ 5.3284e-03, -3.4830e-02, -1.3133e-02,  9.9028e-04,  2.1711e-02,\n",
      "        -1.2323e-02, -2.2218e-02, -2.5368e-02, -1.0656e-02, -2.3757e-02,\n",
      "        -1.7491e-02,  2.0906e-02, -3.2918e-05,  8.7540e-03,  2.9819e-02,\n",
      "        -1.8154e-02, -1.0404e-02,  1.5103e-02, -4.1748e-02,  2.5096e-04,\n",
      "         1.5314e-02, -1.8568e-02, -3.1880e-02, -3.0496e-02, -2.4926e-02,\n",
      "         9.6597e-03, -8.6707e-03,  7.2595e-03,  3.6556e-02,  2.1622e-02,\n",
      "         2.2995e-02, -2.2792e-02, -1.5584e-02, -2.0103e-02,  2.0829e-02,\n",
      "         9.2080e-03, -5.6901e-03,  9.8962e-03, -2.3256e-02,  2.5603e-03,\n",
      "        -1.8669e-02, -2.3781e-02, -3.1918e-03, -2.1615e-02, -2.2865e-02,\n",
      "        -4.3247e-02,  2.6522e-03, -1.7087e-02,  3.7315e-03, -1.4708e-02,\n",
      "        -1.6731e-02,  1.1045e-02,  1.0026e-02,  2.1864e-02,  8.7060e-03,\n",
      "         2.3150e-02,  1.5814e-02, -1.5298e-02,  1.1993e-02,  1.4527e-02,\n",
      "         1.1894e-02, -8.4851e-03, -3.9855e-03,  2.5006e-02, -8.8756e-04,\n",
      "        -2.1362e-03, -6.7859e-03, -7.1772e-03, -9.0526e-03,  2.8430e-02,\n",
      "         6.3003e-03,  1.4726e-02, -2.8482e-02, -1.3817e-02,  2.8075e-02,\n",
      "         9.4570e-03, -3.0793e-02,  4.5780e-03,  9.1398e-03, -3.3833e-03,\n",
      "         2.3451e-02,  3.7842e-02,  1.5842e-02, -3.6428e-02, -2.6128e-02,\n",
      "        -3.2306e-02, -1.8227e-02, -3.2229e-02,  7.7772e-03, -8.0566e-03,\n",
      "        -1.9193e-02,  7.4528e-03,  6.5743e-03, -1.3896e-02,  5.7010e-03,\n",
      "         1.0172e-02, -2.9559e-02, -3.3377e-02, -9.0883e-03, -2.4665e-02,\n",
      "        -1.2377e-02, -2.5675e-02,  4.9549e-03,  1.8503e-02,  3.8772e-02,\n",
      "         1.3228e-02,  3.4065e-02,  2.0367e-02,  2.7930e-03, -3.5980e-02,\n",
      "         1.2938e-02, -9.7400e-03,  3.0513e-02,  2.4437e-02, -3.3090e-02,\n",
      "         6.0581e-03,  3.9726e-03, -1.4393e-02, -5.2105e-03, -8.4642e-03,\n",
      "        -4.2984e-02,  2.1346e-02, -9.2020e-03, -8.8418e-03,  2.6682e-02,\n",
      "         1.7134e-02,  1.6670e-02, -2.6913e-02, -1.9709e-02,  1.4464e-02,\n",
      "         6.0968e-03, -8.7723e-03,  5.2002e-02,  2.3188e-02,  1.5253e-02,\n",
      "        -3.0177e-02,  3.4883e-03, -1.7942e-02, -2.0649e-02,  3.2470e-02,\n",
      "         2.3944e-03, -2.5297e-02,  1.3624e-02, -1.8732e-03,  1.3749e-02,\n",
      "         2.0952e-03, -2.4991e-02, -1.2455e-03, -1.9930e-02,  9.5517e-03,\n",
      "         3.4406e-02,  3.7138e-02,  1.7718e-02, -1.9562e-02, -3.6282e-02,\n",
      "         1.4534e-02, -3.7352e-02, -4.3976e-03, -9.7440e-03, -9.9981e-03,\n",
      "         1.3198e-02, -2.9006e-02, -2.5710e-02, -1.9243e-02, -1.3565e-02,\n",
      "        -5.5266e-02, -5.7135e-03,  7.5060e-04, -2.3936e-03, -4.7967e-04,\n",
      "        -1.8130e-02,  1.0622e-02,  2.4038e-02,  1.6929e-02, -8.4018e-03,\n",
      "         1.9779e-02, -2.4490e-02,  2.8546e-02,  2.1385e-03, -2.6291e-03,\n",
      "        -8.7573e-03,  2.4483e-02, -8.0310e-04, -1.0056e-02,  2.0714e-02,\n",
      "         1.7775e-02, -1.9040e-02, -9.1464e-03,  3.2060e-02, -1.8263e-02,\n",
      "        -3.6859e-02,  9.0391e-03,  4.1212e-03, -8.3531e-03, -1.5846e-02,\n",
      "         1.5923e-03,  3.3731e-04, -1.6335e-02, -4.1017e-02,  1.3123e-02,\n",
      "        -3.1595e-02,  1.0500e-02,  1.4186e-02,  1.4949e-02,  2.4229e-02,\n",
      "        -5.2789e-03,  5.5581e-03, -1.0949e-02, -9.4909e-03,  5.6737e-03,\n",
      "        -2.2029e-03, -2.3227e-02, -3.3062e-02,  2.3902e-02,  1.0191e-02,\n",
      "        -3.5517e-02, -2.3629e-03,  5.4538e-03,  8.3885e-03, -1.9535e-02,\n",
      "        -2.8529e-02, -1.2882e-02,  9.0856e-03,  8.5643e-03, -8.5603e-03,\n",
      "         1.1822e-02,  3.5631e-02, -2.1358e-02, -1.8366e-02, -6.5308e-03,\n",
      "         3.5470e-02,  2.0411e-02, -6.9745e-03,  7.4365e-03, -3.3476e-02,\n",
      "         8.2972e-03, -3.7479e-03,  7.1580e-03, -8.2481e-03,  2.3138e-02,\n",
      "         1.3102e-02, -3.5981e-03, -1.0308e-02,  9.6747e-03,  7.2526e-03,\n",
      "         1.4616e-02, -8.9770e-03,  4.1214e-02, -9.3562e-03,  2.9108e-04,\n",
      "         2.6803e-02, -2.8384e-02,  1.6716e-02, -5.9512e-03, -1.8942e-02,\n",
      "         1.6043e-02, -1.1604e-02,  1.1886e-02,  4.0045e-03,  6.8902e-03,\n",
      "        -1.7916e-02,  9.5302e-04, -3.5295e-02,  2.5708e-02,  3.7027e-03,\n",
      "        -1.3035e-02,  4.2134e-02,  9.7378e-03,  2.3531e-02,  9.2917e-03,\n",
      "         3.3162e-02, -2.2942e-02,  1.4590e-02, -1.9886e-02,  2.3518e-02,\n",
      "         3.7376e-02, -7.4270e-03, -3.8610e-02,  6.4136e-03, -1.9191e-02,\n",
      "         1.1351e-02, -1.1254e-02,  2.4997e-02, -4.5836e-02, -7.0906e-03,\n",
      "        -2.1923e-02,  1.8183e-02,  4.8501e-03,  1.7229e-02,  2.5549e-02,\n",
      "        -3.4426e-03,  1.0485e-02, -1.7434e-02, -2.4835e-02,  1.5788e-03,\n",
      "        -6.7530e-03,  1.1100e-02, -1.2813e-02, -1.7788e-02,  1.1201e-02,\n",
      "        -4.6697e-03,  1.0847e-02, -1.4055e-02, -1.5197e-02,  2.8901e-02,\n",
      "         1.9571e-03, -9.5909e-03, -5.5612e-02, -6.6115e-03, -9.3331e-03,\n",
      "         8.5490e-03, -1.9215e-02,  1.0165e-02, -1.2172e-02,  4.5902e-02,\n",
      "         1.6289e-02,  2.2615e-02,  2.8880e-02, -3.4589e-02, -2.0396e-02,\n",
      "         2.0559e-02,  1.5292e-02,  9.2055e-03,  2.0167e-02,  1.2676e-02,\n",
      "        -2.7040e-02, -2.8053e-02, -5.9086e-03, -1.2013e-02,  9.5606e-03,\n",
      "         4.1053e-03, -1.6494e-02, -2.7696e-02, -9.6109e-03,  2.0680e-02,\n",
      "        -5.8786e-03, -2.0110e-02, -1.6177e-02,  4.0361e-02, -3.7030e-02,\n",
      "        -1.0029e-04, -1.5412e-02,  7.5328e-03, -9.3658e-03,  4.3076e-02,\n",
      "        -2.9257e-02,  2.6367e-02,  1.9643e-02,  1.7337e-02,  3.7200e-02,\n",
      "         1.0944e-02,  7.7908e-03,  1.3692e-03,  6.7752e-03,  5.2857e-03,\n",
      "        -9.6995e-03,  1.1253e-02,  2.2875e-03,  1.6001e-02,  4.5289e-02,\n",
      "         4.3862e-02, -4.3177e-02, -1.1030e-03, -1.5619e-02,  2.3239e-02,\n",
      "         2.3531e-02, -7.4074e-04, -2.8841e-03, -2.9982e-02,  2.0017e-02,\n",
      "         1.1519e-02,  2.5313e-02, -3.4169e-02, -3.9812e-02, -2.2880e-03,\n",
      "        -2.1483e-02, -4.0114e-02, -2.1273e-04, -8.9737e-03, -1.9565e-02,\n",
      "         9.2519e-04, -2.6653e-02,  2.5955e-02, -8.8205e-03,  1.2088e-02,\n",
      "        -1.1509e-02,  2.2771e-02,  1.7226e-02, -1.4398e-03, -2.0532e-02,\n",
      "        -9.6194e-03,  2.5160e-02,  2.0930e-02,  4.8794e-02, -7.8438e-03,\n",
      "         9.4403e-03, -3.0502e-02, -2.2604e-02, -3.3461e-02,  1.5353e-03,\n",
      "         2.1325e-02, -3.3219e-02, -1.4941e-02, -1.9164e-02, -1.5755e-02,\n",
      "        -2.6618e-02, -1.4957e-02,  1.8314e-02,  2.4027e-02, -3.0761e-02,\n",
      "        -4.1526e-02, -1.8327e-02, -5.4407e-04,  5.5571e-03, -2.4329e-02,\n",
      "        -7.3794e-03,  2.5600e-02,  1.3451e-02, -3.3872e-02,  1.6441e-02,\n",
      "         5.1030e-03, -1.1212e-02,  7.1889e-03, -1.9236e-02,  1.7047e-02,\n",
      "         8.0753e-03,  2.4321e-02, -1.8251e-03, -1.1607e-02, -2.6188e-03,\n",
      "         4.7350e-03,  1.8592e-02,  3.4491e-03, -1.2023e-02,  3.2898e-02,\n",
      "        -2.7051e-02, -9.5997e-03,  9.7316e-03,  1.0808e-02, -1.9543e-02,\n",
      "         5.0978e-04, -3.5361e-02, -1.0028e-02,  5.5459e-03, -2.3538e-02,\n",
      "         3.0513e-02, -1.7883e-02,  1.2217e-02,  9.4673e-03,  6.6001e-03,\n",
      "         5.2192e-02, -8.8399e-03, -8.2203e-03, -2.6849e-02,  1.3487e-02,\n",
      "        -2.3971e-02, -2.6757e-02, -5.1402e-02, -1.5019e-02, -3.9115e-02,\n",
      "         1.8202e-02,  3.1838e-02,  4.8148e-03, -2.4155e-02, -1.1291e-02,\n",
      "         2.0805e-02, -9.4818e-03,  1.8892e-02,  1.3994e-02,  4.8154e-02,\n",
      "        -4.1832e-02, -1.6434e-02,  8.1889e-03,  1.0271e-02, -3.1922e-02,\n",
      "         3.7330e-02,  5.6181e-03,  2.9536e-02, -1.0949e-02, -3.7537e-02,\n",
      "         1.1152e-02, -1.5442e-03, -2.4862e-03,  1.9851e-02, -7.6827e-03,\n",
      "        -1.6328e-02,  1.7171e-02, -2.4498e-03, -1.3118e-02, -2.2515e-02,\n",
      "         1.8404e-02, -9.4857e-03, -1.8847e-02, -1.2898e-02,  9.0678e-03,\n",
      "        -1.6423e-02, -3.4674e-03,  1.1957e-02, -9.3740e-03, -1.4653e-02,\n",
      "        -1.0102e-02,  1.4401e-02, -1.4470e-02, -2.2285e-02,  2.1461e-02,\n",
      "        -1.8749e-02,  7.0551e-03,  6.9692e-03, -2.5091e-03, -3.2960e-02,\n",
      "        -1.8303e-02,  1.3151e-02,  3.3097e-02,  4.9891e-03,  1.4020e-02,\n",
      "        -6.9360e-03, -3.8453e-03, -3.2842e-02,  2.1315e-03,  1.8836e-02,\n",
      "        -3.9364e-02,  3.7866e-03,  1.3894e-02, -1.5531e-02,  1.2248e-02,\n",
      "         4.3429e-03,  1.7506e-02,  2.9119e-02, -2.7760e-02, -1.7135e-02,\n",
      "        -4.2987e-03,  8.9915e-04,  6.1506e-04,  3.1075e-02, -3.6667e-02,\n",
      "        -1.8707e-02,  2.3323e-02, -3.1024e-02, -9.6482e-03,  4.3234e-02,\n",
      "         1.7270e-02, -7.3270e-03,  1.3621e-02, -1.6588e-03,  1.0463e-02,\n",
      "        -3.0876e-02,  1.3624e-02,  1.7993e-02, -1.5045e-02,  4.6671e-03,\n",
      "         3.2741e-02,  3.8559e-03,  4.5831e-02, -8.8214e-03,  4.6338e-02,\n",
      "        -3.0449e-03,  3.1979e-03,  4.2978e-04, -7.6262e-03, -2.1208e-02,\n",
      "         1.5457e-02,  2.7819e-02,  3.2274e-02,  2.3787e-02,  8.9297e-03,\n",
      "        -1.5573e-02, -1.1102e-02,  1.9376e-02, -1.2704e-02, -3.3349e-02,\n",
      "        -5.5062e-04,  5.1034e-02,  2.7588e-02,  3.3074e-03, -1.8915e-02,\n",
      "         6.8881e-03,  2.7922e-02, -9.3787e-03, -1.6196e-02, -1.2570e-02,\n",
      "         9.0268e-04,  9.3465e-03, -1.3038e-02, -2.9715e-03,  7.4507e-03,\n",
      "         6.7861e-03,  5.5641e-03, -1.6176e-02, -1.4460e-02, -2.3494e-02,\n",
      "        -1.3498e-02,  1.1477e-02, -1.9588e-02, -6.2951e-02,  7.7118e-03,\n",
      "         5.5646e-03,  1.5731e-02, -6.9956e-03, -4.6602e-03,  5.2508e-03,\n",
      "         6.2982e-03, -4.8809e-02,  2.2905e-03, -2.6062e-02,  2.6268e-02,\n",
      "         5.3963e-03,  8.6092e-03, -5.8150e-04,  7.8622e-03,  1.3819e-02,\n",
      "        -2.0372e-02,  1.1258e-04,  3.8021e-02,  3.2291e-03, -3.9617e-03,\n",
      "         2.0948e-02,  2.0046e-03,  3.4776e-02,  6.0656e-03,  5.4583e-03,\n",
      "         1.2919e-03, -2.4576e-02, -2.3754e-02, -5.1488e-03, -2.2754e-03,\n",
      "         1.1143e-02,  1.6321e-02,  1.6477e-02,  3.8969e-03, -9.1305e-03,\n",
      "         1.5328e-02, -3.8496e-02, -2.0831e-02, -2.5252e-02, -1.0175e-02,\n",
      "        -9.0345e-03, -3.6338e-03, -5.3821e-02,  2.5402e-03,  1.7987e-02,\n",
      "        -1.7162e-03, -2.0252e-02,  3.9195e-03, -3.8551e-03, -1.6270e-02,\n",
      "         7.4741e-03, -4.0332e-03, -3.7166e-02, -5.0227e-03, -1.4031e-03,\n",
      "        -2.9648e-02,  2.7290e-02, -5.1609e-03, -1.1319e-02, -2.9065e-02,\n",
      "        -5.8438e-02, -1.1928e-02,  1.1019e-03, -1.5250e-02, -1.0366e-02,\n",
      "        -9.7888e-03, -1.0904e-04,  2.5545e-02,  2.1947e-04,  1.9069e-02,\n",
      "         2.8284e-02, -7.4775e-03, -1.3842e-02, -2.5527e-02,  2.6018e-03,\n",
      "         1.9622e-02,  2.7611e-02, -1.0924e-02,  7.7691e-03, -4.0856e-02,\n",
      "        -1.2635e-02, -1.1855e-02,  1.3430e-02,  1.3335e-02,  1.1567e-02,\n",
      "        -1.0476e-02,  5.1772e-03, -1.8300e-02, -2.5399e-02, -5.9503e-03,\n",
      "        -5.9231e-03, -2.5349e-02, -5.0700e-03,  8.8174e-03,  1.3733e-02,\n",
      "        -4.4758e-03,  7.1479e-03,  3.4020e-03, -2.4404e-02, -2.1404e-02,\n",
      "         4.0410e-02, -3.6096e-03,  1.1114e-02,  4.5684e-03,  1.5775e-02,\n",
      "         1.3876e-02,  2.4733e-02,  1.0187e-02, -1.2992e-02,  1.9159e-02,\n",
      "        -1.2304e-02,  1.1217e-03, -6.0469e-03, -9.9955e-03, -9.7805e-03,\n",
      "        -6.4986e-03,  2.3340e-02,  1.4724e-02, -9.2288e-03, -7.8787e-03,\n",
      "         1.2276e-02,  1.4797e-02, -1.0875e-02, -1.1243e-02,  5.4424e-03,\n",
      "         9.5492e-03,  1.7725e-03, -7.6593e-03,  3.5454e-03, -1.7486e-02,\n",
      "         2.8449e-02,  1.6478e-02,  2.4708e-03,  2.2474e-03,  9.0420e-03,\n",
      "         6.5089e-03,  1.2144e-04, -1.5060e-02,  2.3008e-02, -2.9014e-02,\n",
      "        -4.9735e-02, -2.4137e-03,  1.9578e-02, -2.5321e-02,  2.1328e-02,\n",
      "         1.9793e-02, -1.3376e-02,  2.9906e-02,  2.6452e-02,  6.8296e-03,\n",
      "        -1.2710e-03, -1.1297e-02,  1.3668e-02,  7.3021e-03, -1.5665e-04,\n",
      "         1.2167e-02, -1.7461e-02,  1.7765e-02, -4.0209e-03, -2.4668e-02,\n",
      "         9.1471e-03, -2.0516e-02,  1.0395e-02, -3.7819e-02, -2.8988e-03,\n",
      "         3.6357e-04,  4.2045e-02,  2.5831e-02, -6.4805e-03,  1.5197e-02,\n",
      "         4.6890e-02, -1.1016e-02,  1.3959e-02], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "print(len(tokenizer))  # 28996\n",
    "tokenizer.add_tokens(['[ENTITY1]','[END_ENTITY1]','[ENTITY2]','[END_ENTITY2]'])\n",
    "print(len(tokenizer))  # 28997\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer)) \n",
    "# The new vector is added at the end of the embedding matrix\n",
    "\n",
    "#print(model.embeddings.word_embeddings.weight[-1, :])\n",
    "# Randomly generated matrix\n",
    "\n",
    "#model.embeddings.word_embeddings.weight[-1, :] = torch.zeros([model.config.hidden_size])\n",
    "\n",
    "#print(model.embeddings.word_embeddings.weight[-1, :])\n",
    "# outputs a vector of zeros of shape [768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74896eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8992e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "- Enter entity token around the sequence\n",
    "- Replace with equal length entity token E1, E1, \\E1\n",
    "- Replace with single entity token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4726f562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['Merpati', 'flight', '106', 'departed', 'Jakarta', '(', 'CGK', ')', 'on', 'a', 'domestic', 'flight', 'to', 'Tanjung', 'Pandan', '(', 'TJQ', ')', '.'], 'h': ['tjq', 'Q1331049', [[16]]], 't': ['tanjung pandan', 'Q3056359', [[13, 14]]]}\n"
     ]
    }
   ],
   "source": [
    "print(js_ls['P931'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
